{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de Regressão Logística para Classificação de Texto\n",
    "\n",
    "Este notebook implementa um modelo de regressão logística para classificar textos em categorias como 'AI' ou 'Human'. Vamos utilizar os dados de entrada fornecidos, aplicar o pré-processamento, treinar o modelo e gerar previsões para um novo conjunto de dados.\n",
    "\n",
    "## Passos:\n",
    "1. Carregar e pré-processar os dados.\n",
    "2. Implementar a regressão logística.\n",
    "3. Treinar o modelo e fazer previsões.\n",
    "4. Salvar as previsões num arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar e Pré-processar os Dados\n",
    "\n",
    "Aqui carregamos os conjuntos de dados de entrada e saída e pré-processamos os dados. A coluna de rótulos 'Label' é transformada de 'AI' para 1 e 'Human' para 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "dataset2_inputs = pd.read_csv('data/dataset2_inputs.csv', delimiter='\\t')\n",
    "test_in = pd.read_csv('data/test_in.csv', delimiter='\\t')\n",
    "test_out = pd.read_csv('data/teste_out.csv', delimiter='\\t')\n",
    "\n",
    "# Pré-processar os dados\n",
    "X_train = test_in['Text']\n",
    "y_train = test_out['Label'].apply(lambda x: 1 if x == 'AI' else 0)  # 'AI' = 1, 'Human' = 0\n",
    "\n",
    "# Tokenização e vetorização dos dados usando CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "X_train_vect = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementação da Regressão Logística\n",
    "\n",
    "A seguir, implementamos a função para a regressão logística, que utiliza a função de ativação sigmoide e realiza a descida do gradiente para otimizar os parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para regressão logística\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(X, y, learning_rate=0.01, epochs=100):\n",
    "    m, n = X.shape\n",
    "    # Inicializar os pesos\n",
    "    W = np.zeros(n)\n",
    "    b = 0\n",
    "\n",
    "    # Descida do gradiente\n",
    "    for epoch in range(epochs):\n",
    "        # Modelo linear\n",
    "        model = np.dot(X, W) + b\n",
    "        # Probabilidades previstas\n",
    "        predictions = sigmoid(model)\n",
    "\n",
    "        # Cálculo dos gradientes\n",
    "        dw = (1/m) * np.dot(X.T, (predictions - y))\n",
    "        db = (1/m) * np.sum(predictions - y)\n",
    "\n",
    "        # Atualizar os parâmetros\n",
    "        W -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "    return W, b\n",
    "\n",
    "def predict(X, W, b):\n",
    "    model = np.dot(X, W) + b\n",
    "    predictions = sigmoid(model)\n",
    "    return [1 if p >= 0.5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinar o Modelo e Fazer Previsões\n",
    "\n",
    "Agora treinamos o modelo utilizando os dados de treinamento e, em seguida, aplicamos o modelo treinado para fazer previsões sobre o conjunto de dados `dataset2_inputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "W, b = logistic_regression(X_train_vect, y_train, learning_rate=0.01, epochs=100)\n",
    "\n",
    "# Carregar e pré-processar o dataset2_inputs para previsão\n",
    "X_input = dataset2_inputs['Text']\n",
    "X_input_vect = vectorizer.transform(X_input).toarray()\n",
    "\n",
    "# Prever os resultados usando o modelo treinado\n",
    "predictions = predict(X_input_vect, W, b)\n",
    "\n",
    "# Mapear as previsões para os rótulos ('AI' ou 'Human')\n",
    "predicted_labels = ['AI' if p == 1 else 'Human' for p in predictions]\n",
    "\n",
    "# Criar o DataFrame de saída\n",
    "dataset2_inputs['Predicted_Label'] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Salvar as Previsões em um Arquivo CSV\n",
    "\n",
    "Por fim, salvamos as previsões geradas no formato CSV, com as colunas 'ID' e 'Predicted_Label', como solicitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar as previsões num arquivo CSV no mesmo formato de entrada\n",
    "dataset2_inputs[['ID', 'Predicted_Label']].to_csv('data/dataset2_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "\n",
    "As previsões geradas foram salvas em `data/dataset2_predictions.csv`. Pode verificar as previsões geradas para o conjunto `dataset2_inputs`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
