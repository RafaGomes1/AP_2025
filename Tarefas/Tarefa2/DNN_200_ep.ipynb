{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3000, 15894)\n",
      "(3000, 15894) (3000, 1) (1000, 15894) (1000, 1)\n",
      "Epoch 1/200 - loss: 2132.5767 - accuracy: 0.4890\n",
      "Epoch 2/200 - loss: 2084.8617 - accuracy: 0.4940\n",
      "Epoch 3/200 - loss: 2082.4654 - accuracy: 0.4957\n",
      "Epoch 4/200 - loss: 2081.2541 - accuracy: 0.5060\n",
      "Epoch 5/200 - loss: 2080.1295 - accuracy: 0.5117\n",
      "Epoch 6/200 - loss: 2078.0194 - accuracy: 0.5107\n",
      "Epoch 7/200 - loss: 2076.0092 - accuracy: 0.5200\n",
      "Epoch 8/200 - loss: 2074.5780 - accuracy: 0.5153\n",
      "Epoch 9/200 - loss: 2073.0273 - accuracy: 0.5260\n",
      "Epoch 10/200 - loss: 2071.2707 - accuracy: 0.5380\n",
      "Epoch 11/200 - loss: 2071.2069 - accuracy: 0.5370\n",
      "Epoch 12/200 - loss: 2067.7563 - accuracy: 0.5423\n",
      "Epoch 13/200 - loss: 2066.6441 - accuracy: 0.5373\n",
      "Epoch 14/200 - loss: 2063.9117 - accuracy: 0.5513\n",
      "Epoch 15/200 - loss: 2062.4139 - accuracy: 0.5460\n",
      "Epoch 16/200 - loss: 2059.1204 - accuracy: 0.5593\n",
      "Epoch 17/200 - loss: 2057.5700 - accuracy: 0.5603\n",
      "Epoch 18/200 - loss: 2055.1441 - accuracy: 0.5697\n",
      "Epoch 19/200 - loss: 2051.7185 - accuracy: 0.5813\n",
      "Epoch 20/200 - loss: 2048.3683 - accuracy: 0.5877\n",
      "Epoch 21/200 - loss: 2045.1566 - accuracy: 0.5850\n",
      "Epoch 22/200 - loss: 2040.9349 - accuracy: 0.5920\n",
      "Epoch 23/200 - loss: 2037.6501 - accuracy: 0.5997\n",
      "Epoch 24/200 - loss: 2031.4863 - accuracy: 0.6010\n",
      "Epoch 25/200 - loss: 2027.3328 - accuracy: 0.6060\n",
      "Epoch 26/200 - loss: 2021.2302 - accuracy: 0.6193\n",
      "Epoch 27/200 - loss: 2014.8720 - accuracy: 0.6277\n",
      "Epoch 28/200 - loss: 2007.6635 - accuracy: 0.6247\n",
      "Epoch 29/200 - loss: 2000.0554 - accuracy: 0.6437\n",
      "Epoch 30/200 - loss: 1991.6545 - accuracy: 0.6350\n",
      "Epoch 31/200 - loss: 1981.3470 - accuracy: 0.6537\n",
      "Epoch 32/200 - loss: 1970.4436 - accuracy: 0.6610\n",
      "Epoch 33/200 - loss: 1959.0189 - accuracy: 0.6617\n",
      "Epoch 34/200 - loss: 1944.7497 - accuracy: 0.6750\n",
      "Epoch 35/200 - loss: 1929.5876 - accuracy: 0.6753\n",
      "Epoch 36/200 - loss: 1912.1590 - accuracy: 0.6847\n",
      "Epoch 37/200 - loss: 1893.3925 - accuracy: 0.6840\n",
      "Epoch 38/200 - loss: 1872.3974 - accuracy: 0.6973\n",
      "Epoch 39/200 - loss: 1850.1326 - accuracy: 0.7090\n",
      "Epoch 40/200 - loss: 1823.7179 - accuracy: 0.7130\n",
      "Epoch 41/200 - loss: 1796.0751 - accuracy: 0.7200\n",
      "Epoch 42/200 - loss: 1765.6206 - accuracy: 0.7267\n",
      "Epoch 43/200 - loss: 1734.5769 - accuracy: 0.7317\n",
      "Epoch 44/200 - loss: 1698.3793 - accuracy: 0.7437\n",
      "Epoch 45/200 - loss: 1664.7054 - accuracy: 0.7440\n",
      "Epoch 46/200 - loss: 1624.7651 - accuracy: 0.7553\n",
      "Epoch 47/200 - loss: 1586.2935 - accuracy: 0.7617\n",
      "Epoch 48/200 - loss: 1546.5998 - accuracy: 0.7687\n",
      "Epoch 49/200 - loss: 1506.7478 - accuracy: 0.7783\n",
      "Epoch 50/200 - loss: 1465.1945 - accuracy: 0.7857\n",
      "Epoch 51/200 - loss: 1425.4223 - accuracy: 0.7920\n",
      "Epoch 52/200 - loss: 1382.8706 - accuracy: 0.7977\n",
      "Epoch 53/200 - loss: 1343.7499 - accuracy: 0.8037\n",
      "Epoch 54/200 - loss: 1304.8161 - accuracy: 0.8163\n",
      "Epoch 55/200 - loss: 1266.9713 - accuracy: 0.8210\n",
      "Epoch 56/200 - loss: 1231.7941 - accuracy: 0.8307\n",
      "Epoch 57/200 - loss: 1195.3827 - accuracy: 0.8313\n",
      "Epoch 58/200 - loss: 1162.4236 - accuracy: 0.8370\n",
      "Epoch 59/200 - loss: 1130.8293 - accuracy: 0.8430\n",
      "Epoch 60/200 - loss: 1101.6598 - accuracy: 0.8480\n",
      "Epoch 61/200 - loss: 1073.7140 - accuracy: 0.8493\n",
      "Epoch 62/200 - loss: 1045.7076 - accuracy: 0.8543\n",
      "Epoch 63/200 - loss: 1019.2911 - accuracy: 0.8590\n",
      "Epoch 64/200 - loss: 991.8185 - accuracy: 0.8643\n",
      "Epoch 65/200 - loss: 963.7568 - accuracy: 0.8710\n",
      "Epoch 66/200 - loss: 941.0529 - accuracy: 0.8717\n",
      "Epoch 67/200 - loss: 915.0614 - accuracy: 0.8783\n",
      "Epoch 68/200 - loss: 895.5037 - accuracy: 0.8820\n",
      "Epoch 69/200 - loss: 872.7630 - accuracy: 0.8857\n",
      "Epoch 70/200 - loss: 851.9046 - accuracy: 0.8873\n",
      "Epoch 71/200 - loss: 832.6690 - accuracy: 0.8917\n",
      "Epoch 72/200 - loss: 811.0283 - accuracy: 0.8913\n",
      "Epoch 73/200 - loss: 795.0849 - accuracy: 0.8923\n",
      "Epoch 74/200 - loss: 773.6232 - accuracy: 0.8967\n",
      "Epoch 75/200 - loss: 757.9416 - accuracy: 0.8967\n",
      "Epoch 76/200 - loss: 743.2065 - accuracy: 0.8993\n",
      "Epoch 77/200 - loss: 728.6912 - accuracy: 0.9027\n",
      "Epoch 78/200 - loss: 712.6816 - accuracy: 0.9057\n",
      "Epoch 79/200 - loss: 697.9848 - accuracy: 0.9083\n",
      "Epoch 80/200 - loss: 683.5859 - accuracy: 0.9123\n",
      "Epoch 81/200 - loss: 670.5459 - accuracy: 0.9153\n",
      "Epoch 82/200 - loss: 655.8033 - accuracy: 0.9153\n",
      "Epoch 83/200 - loss: 644.6072 - accuracy: 0.9160\n",
      "Epoch 84/200 - loss: 632.4552 - accuracy: 0.9203\n",
      "Epoch 85/200 - loss: 621.7259 - accuracy: 0.9200\n",
      "Epoch 86/200 - loss: 610.6567 - accuracy: 0.9220\n",
      "Epoch 87/200 - loss: 599.7859 - accuracy: 0.9243\n",
      "Epoch 88/200 - loss: 588.4877 - accuracy: 0.9273\n",
      "Epoch 89/200 - loss: 578.4317 - accuracy: 0.9273\n",
      "Epoch 90/200 - loss: 568.9699 - accuracy: 0.9307\n",
      "Epoch 91/200 - loss: 558.6713 - accuracy: 0.9297\n",
      "Epoch 92/200 - loss: 548.7670 - accuracy: 0.9307\n",
      "Epoch 93/200 - loss: 542.0850 - accuracy: 0.9337\n",
      "Epoch 94/200 - loss: 535.1304 - accuracy: 0.9330\n",
      "Epoch 95/200 - loss: 526.9055 - accuracy: 0.9347\n",
      "Epoch 96/200 - loss: 520.5419 - accuracy: 0.9370\n",
      "Epoch 97/200 - loss: 509.7551 - accuracy: 0.9383\n",
      "Epoch 98/200 - loss: 501.8164 - accuracy: 0.9383\n",
      "Epoch 99/200 - loss: 494.3581 - accuracy: 0.9397\n",
      "Epoch 100/200 - loss: 487.3308 - accuracy: 0.9427\n",
      "Epoch 101/200 - loss: 481.9539 - accuracy: 0.9423\n",
      "Epoch 102/200 - loss: 474.1209 - accuracy: 0.9427\n",
      "Epoch 103/200 - loss: 471.1966 - accuracy: 0.9447\n",
      "Epoch 104/200 - loss: 465.1213 - accuracy: 0.9450\n",
      "Epoch 105/200 - loss: 460.4199 - accuracy: 0.9453\n",
      "Epoch 106/200 - loss: 457.0123 - accuracy: 0.9457\n",
      "Epoch 107/200 - loss: 452.0860 - accuracy: 0.9470\n",
      "Epoch 108/200 - loss: 446.7603 - accuracy: 0.9457\n",
      "Epoch 109/200 - loss: 442.6421 - accuracy: 0.9477\n",
      "Epoch 110/200 - loss: 439.6861 - accuracy: 0.9487\n",
      "Epoch 111/200 - loss: 435.4923 - accuracy: 0.9473\n",
      "Epoch 112/200 - loss: 431.2680 - accuracy: 0.9487\n",
      "Epoch 113/200 - loss: 425.5788 - accuracy: 0.9503\n",
      "Epoch 114/200 - loss: 420.7768 - accuracy: 0.9497\n",
      "Epoch 115/200 - loss: 416.2201 - accuracy: 0.9513\n",
      "Epoch 116/200 - loss: 412.5596 - accuracy: 0.9517\n",
      "Epoch 117/200 - loss: 409.3995 - accuracy: 0.9523\n",
      "Epoch 118/200 - loss: 406.7380 - accuracy: 0.9507\n",
      "Epoch 119/200 - loss: 401.9555 - accuracy: 0.9523\n",
      "Epoch 120/200 - loss: 396.8453 - accuracy: 0.9527\n",
      "Epoch 121/200 - loss: 392.7422 - accuracy: 0.9540\n",
      "Epoch 122/200 - loss: 389.6013 - accuracy: 0.9550\n",
      "Epoch 123/200 - loss: 385.7529 - accuracy: 0.9550\n",
      "Epoch 124/200 - loss: 383.4228 - accuracy: 0.9540\n",
      "Epoch 125/200 - loss: 379.8651 - accuracy: 0.9573\n",
      "Epoch 126/200 - loss: 375.3821 - accuracy: 0.9567\n",
      "Epoch 127/200 - loss: 371.7690 - accuracy: 0.9567\n",
      "Epoch 128/200 - loss: 369.0415 - accuracy: 0.9567\n",
      "Epoch 129/200 - loss: 366.2597 - accuracy: 0.9583\n",
      "Epoch 130/200 - loss: 362.9113 - accuracy: 0.9590\n",
      "Epoch 131/200 - loss: 359.6821 - accuracy: 0.9587\n",
      "Epoch 132/200 - loss: 356.9355 - accuracy: 0.9607\n",
      "Epoch 133/200 - loss: 353.1674 - accuracy: 0.9600\n",
      "Epoch 134/200 - loss: 350.8288 - accuracy: 0.9610\n",
      "Epoch 135/200 - loss: 347.1745 - accuracy: 0.9617\n",
      "Epoch 136/200 - loss: 345.4703 - accuracy: 0.9617\n",
      "Epoch 137/200 - loss: 343.4520 - accuracy: 0.9627\n",
      "Epoch 138/200 - loss: 341.2465 - accuracy: 0.9630\n",
      "Epoch 139/200 - loss: 340.1779 - accuracy: 0.9620\n",
      "Epoch 140/200 - loss: 336.1739 - accuracy: 0.9627\n",
      "Epoch 141/200 - loss: 332.5333 - accuracy: 0.9637\n",
      "Epoch 142/200 - loss: 330.2167 - accuracy: 0.9647\n",
      "Epoch 143/200 - loss: 326.7701 - accuracy: 0.9647\n",
      "Epoch 144/200 - loss: 324.0453 - accuracy: 0.9643\n",
      "Epoch 145/200 - loss: 321.3655 - accuracy: 0.9660\n",
      "Epoch 146/200 - loss: 319.7621 - accuracy: 0.9650\n",
      "Epoch 147/200 - loss: 317.9430 - accuracy: 0.9653\n",
      "Epoch 148/200 - loss: 315.0698 - accuracy: 0.9670\n",
      "Epoch 149/200 - loss: 312.3881 - accuracy: 0.9663\n",
      "Epoch 150/200 - loss: 309.3188 - accuracy: 0.9660\n",
      "Epoch 151/200 - loss: 306.6182 - accuracy: 0.9667\n",
      "Epoch 152/200 - loss: 304.9072 - accuracy: 0.9670\n",
      "Epoch 153/200 - loss: 303.2507 - accuracy: 0.9680\n",
      "Epoch 154/200 - loss: 298.7814 - accuracy: 0.9677\n",
      "Epoch 155/200 - loss: 297.2811 - accuracy: 0.9683\n",
      "Epoch 156/200 - loss: 295.3757 - accuracy: 0.9677\n",
      "Epoch 157/200 - loss: 293.9395 - accuracy: 0.9687\n",
      "Epoch 158/200 - loss: 292.0000 - accuracy: 0.9680\n",
      "Epoch 159/200 - loss: 289.4164 - accuracy: 0.9697\n",
      "Epoch 160/200 - loss: 287.0795 - accuracy: 0.9700\n",
      "Epoch 161/200 - loss: 286.6648 - accuracy: 0.9693\n",
      "Epoch 162/200 - loss: 284.1045 - accuracy: 0.9680\n",
      "Epoch 163/200 - loss: 282.1274 - accuracy: 0.9690\n",
      "Epoch 164/200 - loss: 280.4967 - accuracy: 0.9700\n",
      "Epoch 165/200 - loss: 279.6628 - accuracy: 0.9710\n",
      "Epoch 166/200 - loss: 275.6501 - accuracy: 0.9697\n",
      "Epoch 167/200 - loss: 274.1554 - accuracy: 0.9703\n",
      "Epoch 168/200 - loss: 271.8222 - accuracy: 0.9720\n",
      "Epoch 169/200 - loss: 270.3149 - accuracy: 0.9713\n",
      "Epoch 170/200 - loss: 268.9810 - accuracy: 0.9727\n",
      "Epoch 171/200 - loss: 267.4800 - accuracy: 0.9720\n",
      "Epoch 172/200 - loss: 266.2947 - accuracy: 0.9717\n",
      "Epoch 173/200 - loss: 264.4920 - accuracy: 0.9730\n",
      "Epoch 174/200 - loss: 262.6286 - accuracy: 0.9733\n",
      "Epoch 175/200 - loss: 261.6935 - accuracy: 0.9730\n",
      "Epoch 176/200 - loss: 260.2763 - accuracy: 0.9730\n",
      "Epoch 177/200 - loss: 258.8075 - accuracy: 0.9740\n",
      "Epoch 178/200 - loss: 257.4662 - accuracy: 0.9733\n",
      "Epoch 179/200 - loss: 256.3597 - accuracy: 0.9737\n",
      "Epoch 180/200 - loss: 254.6957 - accuracy: 0.9733\n",
      "Epoch 181/200 - loss: 253.3814 - accuracy: 0.9750\n",
      "Epoch 182/200 - loss: 250.9546 - accuracy: 0.9747\n",
      "Epoch 183/200 - loss: 249.7873 - accuracy: 0.9750\n",
      "Epoch 184/200 - loss: 247.6210 - accuracy: 0.9763\n",
      "Epoch 185/200 - loss: 246.6525 - accuracy: 0.9753\n",
      "Epoch 186/200 - loss: 245.0163 - accuracy: 0.9750\n",
      "Epoch 187/200 - loss: 243.9994 - accuracy: 0.9760\n",
      "Epoch 188/200 - loss: 241.4579 - accuracy: 0.9760\n",
      "Epoch 189/200 - loss: 241.3252 - accuracy: 0.9773\n",
      "Epoch 190/200 - loss: 238.6162 - accuracy: 0.9760\n",
      "Epoch 191/200 - loss: 236.9374 - accuracy: 0.9770\n",
      "Epoch 192/200 - loss: 236.1535 - accuracy: 0.9767\n",
      "Epoch 193/200 - loss: 234.4145 - accuracy: 0.9780\n",
      "Epoch 194/200 - loss: 233.5656 - accuracy: 0.9777\n",
      "Epoch 195/200 - loss: 232.7084 - accuracy: 0.9760\n",
      "Epoch 196/200 - loss: 232.4012 - accuracy: 0.9787\n",
      "Epoch 197/200 - loss: 230.9781 - accuracy: 0.9770\n",
      "Epoch 198/200 - loss: 230.4926 - accuracy: 0.9783\n",
      "Epoch 199/200 - loss: 227.7579 - accuracy: 0.9790\n",
      "Epoch 200/200 - loss: 226.7922 - accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imports do modelo\n",
    "from layers import SigmoidActivation, DenseLayer\n",
    "from functions import BinaryCrossEntropy, accuracy\n",
    "from networks import NeuralNetwork\n",
    "from optimizations import RetGradient, L2Reg\n",
    "\n",
    "# Função auxiliar para remover pontuação (opcional)\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Ler ficheiros\n",
    "train_input = pd.read_csv('data/test_input.csv', sep='\\t')\n",
    "train_output = pd.read_csv('data/test_output.csv', sep='\\t')\n",
    "validation_input = pd.read_csv('data/test_in.csv', sep='\\t')\n",
    "validation_output = pd.read_csv('data/teste_out.csv', sep='\\t')\n",
    "test_input = pd.read_csv('data/dataset2_inputs.csv', sep='\\t')  # sem output\n",
    "\n",
    "# Pré-processamento\n",
    "rem_punctuation = False\n",
    "if rem_punctuation:\n",
    "    train_input['Text'] = train_input['Text'].apply(remove_punctuation)\n",
    "    validation_input['Text'] = validation_input['Text'].apply(remove_punctuation)\n",
    "    test_input['Text'] = test_input['Text'].apply(remove_punctuation)\n",
    "\n",
    "# Extrair campos\n",
    "X_train_raw = train_input['Text'].values\n",
    "y_train = train_output['Label'].map(lambda x: 1 if x == 'AI' else 0).astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "X_validation_raw = validation_input['Text'].values\n",
    "y_validation = validation_output['Label'].map(lambda x: 1 if x == 'AI' else 0).astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "X_test_raw = test_input['Text'].values\n",
    "ids = test_input['ID'].values\n",
    "y_test = None  # não fornecido\n",
    "\n",
    "# Vetorização + normalização\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw).toarray()\n",
    "X_validation = vectorizer.transform(X_validation_raw).toarray()\n",
    "X_test = vectorizer.transform(X_test_raw).toarray()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "optimizer = RetGradient(learning_rate=0.001, momentum=0.9)\n",
    "loss = BinaryCrossEntropy()\n",
    "regulator = L2Reg(l2_val=0.001)\n",
    "\n",
    "model = NeuralNetwork(epochs=200, batch_size=30, optimizer=optimizer, regulator=regulator, verbose=True,\n",
    "                      loss=loss, metric=accuracy, patience=20, min_delta=0.001)\n",
    "\n",
    "print('Training set shape:', X_train.shape)\n",
    "print(X_train.shape, y_train.shape, X_validation.shape, y_validation.shape)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "model.add(DenseLayer(64, (n_features,)))\n",
    "model.add(SigmoidActivation())\n",
    "model.add(DenseLayer(32))\n",
    "model.add(SigmoidActivation())\n",
    "model.add(DenseLayer(16))\n",
    "model.add(SigmoidActivation())\n",
    "model.add(DenseLayer(1))\n",
    "model.add(SigmoidActivation())\n",
    "\n",
    "# Train network\n",
    "model.fit(X_train, y_train, X_val=X_validation, y_val=y_validation)\n",
    "\n",
    "# Plot learning curves\n",
    "model.plot_train_curves()\n",
    "\n",
    "# Predict test set\n",
    "out = model.predict(X_test)\n",
    "\n",
    "# Avaliação (opcional)\n",
    "if y_test is not None:\n",
    "    print(model.score(y_test, out))\n",
    "\n",
    "# Guardar resultados\n",
    "results_filepath = 'data/previsao-s1.csv'\n",
    "os.makedirs(os.path.dirname(results_filepath), exist_ok=True)\n",
    "\n",
    "results = pd.DataFrame({'ID': ids, 'Label': ['AI' if round(pred[0]) == 1 else 'Human' for pred in out]})\n",
    "results.to_csv(results_filepath, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
