{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "94/94 [==============================] - 26s 247ms/step - loss: 0.2457 - accuracy: 0.8957 - val_loss: 0.0107 - val_accuracy: 0.9960\n",
      "Epoch 2/6\n",
      "94/94 [==============================] - 21s 227ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9970\n",
      "Epoch 3/6\n",
      "94/94 [==============================] - 22s 236ms/step - loss: 3.3224e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9970\n",
      "Epoch 4/6\n",
      "94/94 [==============================] - 28s 296ms/step - loss: 1.7809e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9970\n",
      "Epoch 5/6\n",
      "94/94 [==============================] - 27s 285ms/step - loss: 1.0909e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9970\n",
      "Epoch 6/6\n",
      "94/94 [==============================] - 27s 288ms/step - loss: 7.1681e-05 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9960\n",
      "4/4 [==============================] - 1s 42ms/step\n",
      "✅ Ficheiro de submissão gerado: submissao2-bilstm.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =====================\n",
    "# 1. Setup e semente\n",
    "# =====================\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# =====================\n",
    "# 2. Carregar dados\n",
    "# =====================\n",
    "def load_dataset(file_path, sep='\\t'):\n",
    "    return pd.read_csv(file_path, sep=sep, encoding='utf-8')\n",
    "\n",
    "X_train = load_dataset(\"data/dataset_training_input.csv\")\n",
    "y_train = load_dataset(\"data/dataset_training_output.csv\")\n",
    "\n",
    "X_val = load_dataset(\"data/dataset_validation_input.csv\")\n",
    "y_val = load_dataset(\"data/dataset_validation_output.csv\")\n",
    "\n",
    "X_test = load_dataset(\"data/dataset3_inputs.csv\")\n",
    "ids = X_test[\"ID\"]\n",
    "\n",
    "# =====================\n",
    "# 3. Tokenização\n",
    "# =====================\n",
    "max_words = 15000\n",
    "max_len = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train[\"Text\"])\n",
    "\n",
    "def tokenize_pad(texts):\n",
    "    seqs = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(seqs, maxlen=max_len)\n",
    "\n",
    "X_train_pad = tokenize_pad(X_train[\"Text\"])\n",
    "X_val_pad = tokenize_pad(X_val[\"Text\"])\n",
    "X_test_pad = tokenize_pad(X_test[\"Text\"])\n",
    "\n",
    "# =====================\n",
    "# 4. Labels\n",
    "# =====================\n",
    "y_train = y_train[\"Label\"].map({\"AI\": 1, \"Human\": 0}).values\n",
    "y_val = y_val[\"Label\"].map({\"AI\": 1, \"Human\": 0}).values\n",
    "\n",
    "# =====================\n",
    "# 5. Modelo Bidirectional LSTM\n",
    "# =====================\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(max_len,)),\n",
    "    Embedding(max_words, embedding_dim),\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# =====================\n",
    "# 6. Treinar\n",
    "# =====================\n",
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=6,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val_pad, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# =====================\n",
    "# 7. Prever no dataset3\n",
    "# =====================\n",
    "preds = model.predict(X_test_pad)\n",
    "pred_labels = [\"AI\" if p > 0.5 else \"Human\" for p in preds.flatten()]\n",
    "\n",
    "# =====================\n",
    "# 8. Guardar submissão\n",
    "# =====================\n",
    "output_df = pd.DataFrame({\n",
    "    \"ID\": ids,\n",
    "    \"Label\": pred_labels\n",
    "})\n",
    "output_df.to_csv(\"data/previsao-Bidirectional-LSTM-s2.csv\", sep=\"\\t\", index=False)\n",
    "print(\"✅ Ficheiro de submissão gerado: submissao2-bilstm.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
