{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb95cd02678911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:31:10.203691Z",
     "start_time": "2025-03-17T21:30:46.419034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, Error: 0.49638004597796964\n",
      "Epoch 1000/10000, Error: 0.017543229847077676\n",
      "Epoch 2000/10000, Error: 0.009791453910807067\n",
      "Epoch 3000/10000, Error: 0.0073402322133975404\n",
      "Epoch 4000/10000, Error: 0.006058067944126904\n",
      "Epoch 5000/10000, Error: 0.005247184159645864\n",
      "Epoch 6000/10000, Error: 0.004678638321979209\n",
      "Epoch 7000/10000, Error: 0.00425318025952555\n",
      "Epoch 8000/10000, Error: 0.003920166515513606\n",
      "Epoch 9000/10000, Error: 0.0036507951632207053\n",
      "Tamanho do dataset2_inputs: 100\n",
      "Tamanho das previsões: 200\n",
      "Previsões geradas e salvas em 'data/dataset2_predictions_mlp.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Funções auxiliares\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def train_mlp(X_train, y_train, X_test, y_test, hidden_units=10, learning_rate=0.01, epochs=10000):\n",
    "    # Inicialização dos pesos e bias\n",
    "    input_layer_size = X_train.shape[1]\n",
    "    output_layer_size = 1\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Pesos e bias para a camada de entrada para camada oculta\n",
    "    W1 = np.random.randn(input_layer_size, hidden_units)\n",
    "    b1 = np.zeros((1, hidden_units))\n",
    "\n",
    "    # Pesos e bias para a camada oculta para camada de saída\n",
    "    W2 = np.random.randn(hidden_units, output_layer_size)\n",
    "    b2 = np.zeros((1, output_layer_size))\n",
    "\n",
    "    # Lista para salvar os erros durante o treinamento\n",
    "    errors = []\n",
    "\n",
    "    # Treinamento\n",
    "    for epoch in range(epochs):\n",
    "        # Feedforward - camadas ocultas\n",
    "        Z1 = np.dot(X_train, W1) + b1\n",
    "        A1 = sigmoid(Z1)\n",
    "\n",
    "        # Camada de saída\n",
    "        Z2 = np.dot(A1, W2) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        # Cálculo do erro\n",
    "        error = y_train.reshape(-1, 1) - A2\n",
    "        errors.append(np.mean(np.abs(error)))\n",
    "\n",
    "        # Backpropagation\n",
    "        dA2 = error * sigmoid_derivative(A2)\n",
    "        dW2 = np.dot(A1.T, dA2)\n",
    "        db2 = np.sum(dA2, axis=0, keepdims=True)\n",
    "\n",
    "        dA1 = np.dot(dA2, W2.T) * sigmoid_derivative(A1)\n",
    "        dW1 = np.dot(X_train.T, dA1)\n",
    "        db1 = np.sum(dA1, axis=0, keepdims=True)\n",
    "\n",
    "        # Atualização dos pesos e bias\n",
    "        W1 += learning_rate * dW1\n",
    "        b1 += learning_rate * db1\n",
    "        W2 += learning_rate * dW2\n",
    "        b2 += learning_rate * db2\n",
    "\n",
    "        # Printar erro a cada 1000 iterações\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Error: {np.mean(np.abs(error))}\")\n",
    "\n",
    "    # Predição nos dados de teste\n",
    "    Z1 = np.dot(X_test, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    predictions = (A2 > 0.5).astype(int).flatten()\n",
    "    return predictions, errors\n",
    "\n",
    "# Carregar e pré-processar os dados\n",
    "dataset2_inputs = pd.read_csv('data/dataset2_inputs.csv', sep='\\t')\n",
    "test_in = pd.read_csv('data/test_in.csv', sep='\\t')\n",
    "test_out = pd.read_csv('data/teste_out.csv', sep='\\t')\n",
    "\n",
    "# Vetorização do texto usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(test_in['Text']).toarray()\n",
    "\n",
    "# Codificação dos rótulos (AI ou Human)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(test_out['Label'])\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo MLP manual\n",
    "predictions, _ = train_mlp(X_train, y_train, X_test, y_test, hidden_units=20, learning_rate=0.01, epochs=10000)\n",
    "\n",
    "# Verificar o tamanho das previsões e do dataset2_inputs\n",
    "print(f\"Tamanho do dataset2_inputs: {dataset2_inputs.shape[0]}\")\n",
    "print(f\"Tamanho das previsões: {len(predictions)}\")\n",
    "\n",
    "# Ajustar as previsões para garantir que a quantidade de previsões seja a mesma que o número de linhas em dataset2_inputs\n",
    "if len(predictions) != dataset2_inputs.shape[0]:\n",
    "    # Se o número de previsões não coincidir, ajustar as previsões\n",
    "    predictions = predictions[:dataset2_inputs.shape[0]]\n",
    "\n",
    "# Agora podemos adicionar as previsões corretamente ao DataFrame\n",
    "predictions_label = label_encoder.inverse_transform(predictions)\n",
    "dataset2_inputs['Predictions'] = predictions_label\n",
    "\n",
    "# Mostrar as previsões no dataset2_inputs e salvar o arquivo CSV\n",
    "dataset2_inputs[['ID', 'Predictions']].to_csv('data/dataset2_predictions_mlp-s1.csv', index=False)\n",
    "\n",
    "print(\"Previsões geradas e salvas em 'data/dataset2_predictions_mlp.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0494348000f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
